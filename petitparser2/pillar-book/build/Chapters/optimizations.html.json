{"content":"<p>\nThis text is part of the PetitParser2 series:\n</p><ul>\n<li><a href=\"Chapters/../chapter1.html\">Extracting Javascript</a></li>\n<li><a href=\"Chapters/../chapter2.html\">From Script to Parser</a></li>\n<li><a href=\"Chapters/../chapter3.html\">Extracting the Structure</a></li>\n<li><a href=\"Chapters/../AST.html\">Abstract Syntax Tree</a></li>\n<li><a href=\"Chapters/../optimizations.html\">Optimizations</a></li>\n<li><a href=\"Chapters/../memoization.html\">Memoization</a></li>\n</ul>\n\n<p>\nAdditional Chapters:\n</p><ul>\n<li><a href=\"Chapters/../matchingTags.html\">Matching Tags</a></li>\n<li><a href=\"Chapters/../smalltalkOptimization.html\">Optimizing Smalltalk Grammar</a></li>\n</ul>\n\n\n<section>\n<h1>Optimizations Overview</h1>\n\n<p class=\"note\">Please note that the <code>WebGrammar</code> exported in the previous chapter contains already optimized version of <code>element</code> rule. In this and the following chapter, we suppose what we stated in <a href=\"chapter3.html\">Extracting the Structure</a> chapter about the <code>element</code> definition, i.e. it looks like this:</p><figure><pre><code class=\"smalltalk\">WebGrammar&gt;&gt;element\n\t^ (elOpen, elContent, elClose)</code></pre><figcaption></figcaption></figure>\n\n\n<section>\n<h2>1. Basic Analysis</h2>\n<p>\nWhen running the <code>testStructuredDocument</code>, you might have noticed that the performance is not good. \nIt is actually terribly bad. Let us inspect in in detail:\n</p>\n<figure><pre><code class=\"smalltalk\">input := PP2Sources current htmlSample.\nWebParser new debug: input.</code></pre><figcaption></figcaption></figure>\n\n<section>\n<h3>Report View</h3>\n<p>\nThis will run the parser in a debug mode, which collects lots of useful information. Unfortunately, it also takes considerable amount of time so be patient. Once you get the result, inspect the Report tab (note that numbers might slightly differ in your case):\n</p>\n<p>\n\n<figure>\n\t<img src=\"figures/unoptimized-report.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n<p>\nThe total stream size is 1171 characters. \nThe parser has remembered the full context 510197 times and restored 387667 times. \nThis means that the full copy of the context (including the stack of opened elements) has been created 510197 times and the context has been restored from this full copy (by doing another copy) 387667 times. \nThis is in average 331 backtrackings per consumed character. \n</p>\n\n<p>\nSome of the parsers do not need to perform the full context copy. \nThese are prefixed with ‘lightweight’. \nIn the lightweight case, only the position is remembered and restored (which is much faster than the full copy of a stack). \nThis happened in average 92 times per character.\n</p>\n\n<p>\nHonestly, these numbers are brutal. \nIn ideal case, the number of full restores should be zero. \nFull remember and restore is very expensive. \nVery often only lightweight remember and restore happens, since many grammars are context-free, i.e. they do not use <code>push</code>, <code>match</code> and <code>pop</code> operators. \n</p>\n<p>\nRegarding the lightweight backtracking, the average of lightweight backtracks per character should be below 1 (in ideal case). \nThis can happen in rase of deterministic grammars, which do not do any (or only a little) speculations and know exactly which alternative of a choice is the correct one. \n</p>\n</section><section>\n<h3>Debug View</h3>\n<p>\nSo why are the numbers so bad in our case? Let us inspect in more detail how this was happening, using the Debug view:\n</p>\n<p>\n\n<figure>\n\t<img src=\"figures/unoptimized-debug.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n<p>\nThe view shows us that 1502165 parsers were invoked to consume the input. \nMost of it (751559 invocations) happened when parsing first two lines of the input - the before water of the sea.\n</p>\n<p>\nThis is too much for such a short input. \nSuch a bad performance is caused by the fact that bounded seas have to verify at every position if the next parser can be parsed. \nIf the next parser happens to be another sea (as in the case of <code>WebGrammar</code>), the number of invocations grows really fast (exponentially in fact). \n</p>\n\n<p>\nWe see that the element rule took approximately one half of the invocations (750598). \nMajority of 751559 invocations of before water were spent by testing for element. \n</p>\n<p>\nAnother glimpse of ineffectivness can be seen in the <code>elOpen</code> rule.\n</p>\n<p>\n<a id=\"elOpenUnoptimized\"></a>\n<figure>\n\t<img src=\"figures/unoptimized-elOpen.png\" width=\"100%%\"/>\n\t<figcaption>0.1. </figcaption>\n</figure>\n</p>\n<p>\nYou can see that the whole <em>&lt;html lang=&quot;html&quot; dir=&quot;ltr&quot; class=&quot;js-enabled&quot;&gt;</em> is parsed by invoking 272 parsers.\nThis is rather too much for a line with 55 characters.\nOne of the reasons is how are the identifiers parsed.\nYou can see that when recognizing the <em>html</em> text, 6 different parsers are invoked; for each letter one and two extra parsers.\n</p>\n</section></section><section>\n<h2>2. Using the <code>optimize</code> method</h2>\n<p>\nLuckily, PetitParser2 comes with an automated optimizations that are able to reduce most of the unnecessary overhead. \nLet it give a try:\n</p>\n<figure><pre><code class=\"smalltalk\">WebParser new optimize debug: input.</code></pre><figcaption></figcaption></figure>\n\n<p>\nThe report looks much better now:\n\n<figure>\n\t<img src=\"figures/optimized-report.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n\n\n<p>\nOnly one full remember, and only 7 lightweight backtracks per character. \nThis is reasonably good for a grammar with bounded seas. \n</p>\n<p class=\"note\">Because of the nature of bounded seas and implementation of PetitParser2, we do not recommend to parse grammars with more complicated bounded seas without optimizations.</p>\n<section>\n<h3>Optimization in Detail</h3>\n<p>\nLet us inspect some of the optimizations that happened. \nLet us try the Debug view:\n</p>\n<p>\n\n<figure>\n\t<img src=\"figures/optimized-debug.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n<p>\nWe see that total number of invoked parsers is 55144, roughly 30x less. \nWe also see that, as in the previous case, most of the parsers were invoked in the before-water of the initial sea, even though roughly 10x less. \nBut we can also notice that the following island and after water are parsed using only 2 and 4 parser invocations respectively! \n</p>\n</section><section>\n<h3>Caches</h3>\n\n<p>\nThe main reason of reduced invocations is caching. \nUnder the <code>element</code> rule, there is a mapping node. \nThe mapping node returns the complete HTML element just in two invocations. \nThe fact that the result has been cached is visualized via the result reference. \n</p>\n\n<p>\nThe reference indicates that at the time of that invocation the result has already been computed during some previous invocation. \nThe parser remembered it and it returned the result without invoking the parser again. \nThis is done by the <code>PP2Cache</code> strategy (you can see its profiling version in the screenshot). The cache has been added to the element during the optimization phase. \n</p>\n\n</section><section>\n<h3>Specializations</h3>\n\n<p>\nAnother optimizations applied by PetitParser two are specializations.\nThe way haw specializations work can be demonstrated on parsing the <em>html</em> text.\n</p>\n<p>\n<a id=\"elOpenOptimized\"></a>\n<figure>\n\t<img src=\"figures/optimized-elOpen.png\" width=\"100%%\"/>\n\t<figcaption>0.2. Optimized parse of <code>elOpen</code></figcaption>\n</figure>\n</p>\n<p>\nOne can see that the text has been recognized using only one invocation contrary to the six invocations in the unoptimized case (see Figure <a href=\"#elOpenUnoptimized\">0.1</a>).\nIn the unoptimized case the <em>html</em> text was parsed using the <em>PossessiveRepeating</em> strategy.\nIn the optimized case (see Figure<a href=\"#elOpenOptimized\">0.2</a>) the strategy used is <em>PlusPredicateObject</em> which is implemented as a while loop without the underlying parser invocations, which is much more efficient.\n</p>\n</section></section><section>\n<h2>3. Caches</h2>\n<p>\nWe already mentioned <code>PP2Cache</code>, but PetitParser2 utilizes four different caches that can be split into two categories:\n</p>\n<ul>\n<li>First category contains fast and memory efficient caches, which remember only the last result of an underlying parser. If it happens that a parser is invoked at the same position again, the result is returned without any parsing. If the position differs, the underlying parser is invoked and the result is remembered for the new position. <ul>\n<li>The fast caches cannot be applied for the context-sensitive parsers, i.e. for parsers whose result depends on some other parameters than a position, e.g. the parser generated from the <code>elClose</code> rule.<s>\n\n\n- The second category contains slower and more memory intense caches, which remember every result for the given position, we call these caches memoizing caches. If it happens that a parser is invoked at any position it has been invoked before, the result is returned without any parsing. </s>Furthermore, if a parser is context-sensitive, the cache uses the whole context as a key.--</li>\n</ul>\n</li>\n</ul>\n\n\n<p>\nYou can inspect the performance of caches in the cache view:\n</p>\n<p>\n\n<figure>\n\t<img src=\"figures/optimized-caches.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n<p>\nThere are three caches visble in the cache view: (i) cache and (ii) trimming cache belong to the first category and (iii) sea memoization cache belongs to the second category. \n</p>\n<section>\n<h3>Cache</h3>\n<dl><dd>Cache improves performance of choice that has alternatives with the same prefix, e.g.:</dd>\n</dl>\n<figure><pre><code class=\"smalltalk\">identifier, $: asPParser not / identifier</code></pre><figcaption></figcaption></figure>\n\n<p>\nNormally, if the identifier is not followed by $:, the parser backtracks and parses identifier again. \nOptimizations of PetitParser2 can detect such a case and enwrap the identifier with a cache, preventing superfluous invocations.\n</p>\n\n</section><section>\n<h3>Trimming Cache</h3>\n<dl><dd>The trimming cache improves the performance of grammars using trimmed tokens, e.g.:</dd>\n</dl>\n<figure><pre><code class=\"smalltalk\">keyword token trim, identifier token trim</code></pre><figcaption></figcaption></figure>\n<p>\nBecause each token trims whitespaces before and after itself, the trimming in between tokens happens twice. \nThe trimming cache prevents this. \n</p>\n</section><section>\n<h3>Sea Memoization Cache</h3>\n<dl><dd>The sea memoization cache is tailored to bounded seas. </dd>\n</dl>\n<p>\nIn some cases, parsing a grammar with bounded can seas result in an exponential complexity, performing lots of redundant work. \nBecause the traditional cache would not be able to reduce the exponential complexity, the seas are memoized.\nThis will preserve the linear complexity of parsing expression grammars.\n</p>\n</section></section><section>\n<h2>4. Specializations</h2>\n<p>\nThe nature of <code>WebGrammar</code> profits mostly from caching optimizations, therefore we describe them in detail in this text.\n</p>\n<p>\nNevertheless, for other grammars, specializations of PetitParser2 significantly speeds up the parser's execution.\nWe investigate specializations in more details in the <a href=\"smalltalkOptimizations.html\">Smalltalk Parser</a> chapter.\n</p>\n<p class=\"todo\">create text about optimization of SmalltalkParser + comparsion with SmaCC.</p>\n</section><section>\n<h2>5. Conclusion</h2>\n<p>\nIn this text we briefly described how inefficiencies of PEG-based parser combinators and we showed how can the <code>optimize</code> method fix most of these.\n</p>\n<p>\nUnfortunatelly, not all the optimizations can be done automatically.\nYou might have noticed that we described only three out of four different caches used in the PetitParser. \nThe last fourth cache is a bit special and we will dedicate a whole <a href=\"memoization.html\">Memoization</a> chapter to it.\n\n</p></section></section>","title":"PetitParser2 and Bounded Seas","Author":"Jan Kurs"}