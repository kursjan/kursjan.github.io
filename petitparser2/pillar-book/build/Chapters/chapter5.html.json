{"content":"<section>\n<h1>Manual Memoization</h1>\n\n<p>\nWe can try to parse the real sources. \nThe home page of we wikipedia, github, facebook and google can be parsed invoking this commands:\n</p>\n<figure><pre><code class=\"smalltalk\">sources := PP2Sources current htmlSourcesAll.\nparser := WebParser new optimize.\nsources collect: [ :s |\n\tparser parse: s.\n]</code></pre><figcaption></figcaption></figure>\n\n<p>\nUnfortunately, this still takes too much time even though we applied the automated optimizations. \nCan we do something, that the optimizations canâ€™t? \n</p>\n<p>\nActually we can. \nIt is a good time to check the events morph of a debug result. Events morph shows timeline of parser invocations (dot) at a given position (x axis) in a given order (y axis).\n</p>\n\n<p>\nInspect a result of the following command again:\n</p>\n<figure><pre><code class=\"smalltalk\">WebParser new optimize debug: input.</code></pre><figcaption></figcaption></figure>\n\n\n<p>\n\n<figure>\n\t<img src=\"figures/optimized-trace.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n\n<p>\nOn a screenshot we see only a part of the story: parsing progress pretty fast towards the end of input. \nThis is the good part. \nBut when scrolling down, one can notice that at some point, parser backtracks and returns to the beginning. \nOver and over again.\nAnd this is the bad part.\n</p>\n\n<p>\nEven though optimizations in PetitParser2 work reasonably good, not all of them can be applied automatically. \nSome grammars do a lot of backtracking which is hard to detect automatically. \nIf I ask you why is the backtracking happening you would probably have a hard time to figure this out. ${footnote:actually, it was not easy for the author of this text to pinpoint the root cause as well}\n</p>\n\n<p>\nLuckily, there are tools to help you. Because of the format of this blog, we will more compact and simplified input.\n</p>\n<figure><pre><code class=\"smalltalk\">compact := '\n&lt;!a&gt;\n&lt;h&gt;\n&lt;m foo&gt;\n&lt;m e&gt;\n&lt;b&gt;\nLorem ipsum donor sit amet\n&lt;/b&gt;\n&lt;/h&gt;\n'.\nWebParser new optimize debug: compact.</code></pre><figcaption></figcaption></figure>\n\n\n<p>\n\n<figure>\n\t<img src=\"figures/short-trace.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n\n<section>\n<h2>I. Searching for the cause</h2>\n\n\n<p>\nIn the events morph we see how is the parser backtracking over and over. \nWe have to play a bit of detective to figure out when and why. \nLet us navigate through the parsing until the body (the b element) is parsed:\n</p>\n\n\n<p>\n\n<figure>\n\t<img src=\"figures/optimized-debug-element.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n\n<p>\nNow switch to the traces tab:\n</p>\n<p>\n\n<figure>\n\t<img src=\"figures/optimized-trace-element.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n\n\n<p>\nThe yellow rectangle highlights 872 underlying invocations of the element rule. \nThe dark red rectangle highlights another invocations of the same element rule that started at the same position. \nAnd we see there are quite a few of them. \nIn general, one does not want to see repeating and high dark rectangles. \nIt simply means redundant computations. \nRemember, each pixel on the y-axis is a parser innvocation.\n</p>\n\n<p>\nWhy do these redundant invocations happen? \nBecause of the unclosed meta elements (named only m in the compact input). \nThe parser sees meta, starts an element, parses the content of meta, including the body element. \nBut it does not find the closing meta. \nSo it returns before the meta element, skips the meta part as a water and continues parsing. Which effectively means it re-parses the body element again. \nThe <code>PP2Cache</code> does not help much, because the last invocation of an element rule is the failed meta element. \nThus the result of the body element is forgotten.\n</p>\n</section><section>\n<h2>II. Fixing the Cause</h2>\n<p>\nThere is a solution to this, called memoization, which remembers all the results for all the positions. \nWe already saw memoizations applied to the bounded seas.\nNow we can suggest to PetitParser2 to try the same trick for the element rule:\n</p>\n<figure><pre><code class=\"smalltalk\">WebGrammar&gt;&gt;element\n\t^ (elOpen, elContent, elClose)\n\t\tmemoize;\n\t\tyourself</code></pre><figcaption></figcaption></figure>\n\n<p>\nWe have to specify memoize manually, because memoization are hard to detect automatically. \nOne has to understand, how is the input structured and how does the parser works to apply it efficiently. \nAnd it is better not to use memoizations superfluously, because they are relatively expensive and not worth in most of the cases.\n</p>\n\n<p>\nLet us check the result now:\n</p>\n<figure><pre><code class=\"smalltalk\">WebParser new optimize debug: compact.</code></pre><figcaption></figcaption></figure>\n\n\n<p>\n\n<figure>\n\t<img src=\"figures/memoized-trace.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n\n<p>\nThis is the result we want to see. \nEven though the parser still backtracks because of the nature of the grammar (i.e. meta rules, we see two big backtrackings, one for each meta in the input), the html body itself is not reparsed over and over again and the precious time is saved.\n</p>\n\n<p>\nYou can try to parse some big sources as well. \nYou will get the results in a reasonable time (considering the simplicity of the grammar and effort we put into specifying it):\n</p>\n<figure><pre><code class=\"smalltalk\">sources := PP2Sources current htmlSourcesAll.\nparser := WebParser new optimize.\nsources collect: [ :s |\n\tparser parse: s.\n]</code></pre><figcaption></figcaption></figure>\n\n<p>\nIf you know how to improve the performance even more, please share the ideas or contribute!\n</p>\n\n<p>\nThe sources can be found here: \n</p><p class=\"todo\">sources</p>\n<p>\nThe image with the VMs for Linux, Mac OS and Windows can be found here:\n</p><p class=\"todo\">image</p></section></section>","title":"PetitParser2 and Bounded Seas","Author":"Jan Kurs"}