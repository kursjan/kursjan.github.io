{"content":"<a id=\"top\"></a>\n<p>\nThis text is part of the <a href=\"Chapters/../../book.html\">Parsing With PetitParser2</a> series.\nThe <a href=\"#toc\">table of content</a> can be found at the end of the chapter.\n\n</p>\n<section>\n<h1>Manual Memoization</h1>\n\n<p class=\"note\">Please note that the <code>WebGrammar</code> offered to download in the <a href=\"AST.html\">Abstract Syntax Tree</a> chapter contains already optimized version of an <code>element</code> rule. In this chapter we suppose that <code>element</code> definition looks like defined in <a href=\"chapter3.html\">Extracting the Structure</a> chapter, i.e. it looks like this:b</p><figure><pre><code class=\"smalltalk\">WebGrammar&gt;&gt;element\n\t^ (elOpen, elContent, elClose)</code></pre><figcaption></figcaption></figure>\n\n\n<p>\nIn the previous chapter <a href=\"optimizations.html\">Optimizations</a> we have greatly improved the performance of our parser. \nSo let's parse the real sources.\nThe home page of we <a href=\"https://wikipedia.org\">wikipedia</a>, <a href=\"https://github.com\">github</a>, <a href=\"https://facebook.com\">facebook</a> and <a href=\"https://google.com\">google</a> can be parsed invoking this commands:\n</p>\n<figure><pre><code class=\"smalltalk\">sources := PP2Sources current htmlSourcesAll.\nparser := WebParser new optimize.\nsources collect: [ :s |\n\tparser parse: s.\n]</code></pre><figcaption></figcaption></figure>\n\n<p>\nUnfortunately, this still takes too much time even though we applied the automated optimizations. \nCan we do something, that the optimizations can't? \nUsually, hard to say. \nIt depends on the nature of a grammar and input to be parsed.\nBut in this case, we can really improve the performance. (obviously, we wouldn't write this chapter otherwise).\n</p>\n<p>\nIt is a good time to check the events morph of a debug result. \nEvents morph shows timeline of parser invocations (dot) at a given position (x axis) in a given time (y axis).\nInspect the result of the following command again and switch to <em>Events</em> view.\n</p>\n<figure><pre><code class=\"smalltalk\">WebParser new optimize debug: input.</code></pre><figcaption></figcaption></figure>\n\n\n<p>\n<a id=\"optimizedTrace\"></a>\n<figure>\n\t<img src=\"figures/optimized-trace.png\" width=\"100%%\"/>\n\t<figcaption>0.1. Visualization of invocations of the optimized parser on input</figcaption>\n</figure>\n</p>\n<p>\nOn the screenshot in Figure <a href=\"#optimizedTrace\">0.1</a> we see only a part of the story (the part that fits into a window).\nThe whole story is that parsing progress pretty fast towards the end of input (this is the good part),  but later one can notice (when scrolling down) that parser jumps to the beginning of input and starts again. \nOver and over again (this is the bad part).\n</p>\n<p class=\"note\">Please not that for long inputs the <em>Event</em> tab shows only a beginning of the input and first few thousands of invocations.</p>\n<p>\nEven though optimizations in PetitParser2 work reasonably well, not all of them can be applied automatically. \nSome grammars do a lot of backtracking and automated optimizations can reduce only part of it.\nIf I ask you why is the backtracking happening you would probably have a hard time to figure this out<sup><a href=\"#footnote1\">[1]</a></sup>.\nSo does have the code trying to apply the optimizations, so we have to do this manually.\n</p>\n\n<p>\nLuckily, there are tools to help us. \nFor convenience of visualization, we use compact and simplified input.\n</p>\n<figure><pre><code class=\"smalltalk\">compact := '\n&lt;!a&gt;\n&lt;h&gt;\n&lt;m foo&gt;\n&lt;m e&gt;\n&lt;b&gt;\nLorem ipsum donor sit amet\n&lt;/b&gt;\n&lt;/h&gt;\n'.\nWebParser new optimize debug: compact.</code></pre><figcaption></figcaption></figure>\n\n\n<p>\n<a id=\"shortTrace\"></a>\n<figure>\n\t<img src=\"figures/short-trace.png\" width=\"100%%\"/>\n\t<figcaption>0.2. Visualization of invocations of the optimized parser on compact input</figcaption>\n</figure>\n</p>\n\n<section>\n<h2>1. Searching for the cause</h2>\n\n\n<p>\nIn the events morph we see how does the parser backtrack, over and over. \nWe have to do a bit of detective work to figure out when and why. \nLet us navigate through the parsing until the HTML body (represented by the <code>b</code> element in the <em>compact</em> input) is parsed:\n</p>\n\n\n<p>\n<a id=\"optimizedDebugElement\"></a>\n<figure>\n\t<img src=\"figures/optimized-debug-element.png\" width=\"100%%\"/>\n\t<figcaption>0.3. Debug view of the <code>element</code> rule</figcaption>\n</figure>\n</p>\n\n<p>\nNow switch to the traces tab:\n</p>\n<p>\n<a id=\"optimizedTraceElement\"></a>\n<figure>\n\t<img src=\"figures/optimized-trace-element.png\" width=\"100%%\"/>\n\t<figcaption>0.4. Debug view of the <code>element</code> rule, traces tab</figcaption>\n</figure>\n</p>\n\n<p>\nThe yellow rectangle in Figure <a href=\"#optimizedTraceElement\">0.4</a> highlights 872 underlying invocations of the <code>element</code> rule. \nThe dark red rectangle highlights another invocations of the same <code>element</code> rule that started at the same position. \nAnd we see there are quite a few of them. \nIn general, one does not want to see repeating dark-red rectangles, and the more of them or the higher these dark-red rectangles are, the worse. \nIt simply means redundant computations. \nRemember, each pixel on the y-axis is a parser invocation.\n</p>\n\n<p>\nWhy do these redundant invocations happen? \nBecause of the unclosed HTML <code>meta</code> elements (represented by <code>m</code> in the <em>compact</em> input). \nThe parser sees meta, starts an element, parses the content of meta, including the body element. \nBut it does not find the closing meta. \nSo it returns before the meta element, skips the meta part as a water and continues parsing. \nThis means it re-parses the body element again. \nThe more <code>meta</code> elements, the worse.\n</p>\n<p>\nIf yo are watchful, you might have noticed a line behind a dark-red bar. \nThis line is created by automated cache, which immediately returns the result of a <code>body</code> element and prevents the whole execution.\nBut because it can remember only the last result, it can prevent only half of the executions.\nTwice as fast is good, but we can do even better.\n</p>\n</section><section>\n<h2>2. Fixing the Cause</h2>\n<p>\nThere is a solution to this, called memoization. \nMemoization is a technique to remember all the results for all the positions (while caching remembered only the last result for the last position).\nThe more power comes at a cost of less efficiency, therefore memoizations should not be used superfluously\n</p><p>\nTo suggest PetitParser2 to add memoization, add a <code>memoize</code> keyword to the <code>element</code> rule.\n</p>\n<figure><pre><code class=\"smalltalk\">WebGrammar&gt;&gt;element\n\t^ (elOpen, elContent, elClose)\n\t\tmemoize;\n\t\tyourself</code></pre><figcaption></figcaption></figure>\n\n<p class=\"note\">Please note currently PetitParser2 does not support memoizations of push and pop parsers. The <em>&quot;neutral&quot;</em> parsers, for example a sequence of push and pop, as in the case of the <code>element</code> rule, can be memoized.</p>\n<p>\nLet us check the result now:\n</p>\n<figure><pre><code class=\"smalltalk\">WebParser new optimize debug: compact.</code></pre><figcaption></figcaption></figure>\n\n\n<p>\n<a id=\"memoizedTrace\"></a>\n<figure>\n\t<img src=\"figures/memoized-trace.png\" width=\"100%%\"/>\n\t<figcaption>0.5. Memoized trace of a compact input</figcaption>\n</figure>\n</p>\n\n<p>\nThe Figure <a href=\"#memoizedTrace\">0.5</a> is the result we want to see. \nEven though the parser still backtracks, it is because of the nature of the grammar.\nGrammar is defined in a way it can speculate and so it speculates. \nWe see two big backtrackings: one for each <code>meta</code> in the input, the html body itself is not re-parsed over and over again and the precious time is saved.\n</p>\n<p class=\"note\">If you want to avoid backtracking of <code>meta</code> elements, you have to include syntax of <code>meta</code> into the grammar.</p>\n\n<p>\nYou can try to parse some big sources as well, they should be parsed in reasonable time:\n</p>\n<figure><pre><code class=\"smalltalk\">sources := PP2Sources current htmlSourcesAll.\nparser := WebParser new optimize.\nsources collect: [ :s |\n\tparser parse: s.\n]</code></pre><figcaption></figcaption></figure>\n\n</section><section>\n<h2>3. Conclusion</h2>\n<p>\nThis is the last chapter about the html parser.\nWe started with a prototype in the playground in the <a href=\"chapter1.html\">first chapter</a> and end up with a full-fledged and tested parser that is able to parse real sources and that is tolerant to malformed inputs. \n</p>\n<p>\nIn each step, we wrote only a code that describes what we are interested in\nand we got feedback from the early stages of the development.\nThis is in contrast with a traditional parser development, where a grammar implementor has to specify most or a complete grammar before obtaining useful results.\n</p>\n<p>\nPetitParser allows a grammar implementor to use such a agile approach to parsing thanks to \n(i) bounded seas, which allows for the tolerant parsing, and (ii) automated optimizations, which significantly improve performance of a removing the burden from the grammar implementor.\n</p>\n<section>\n<h3>Suggestions and ideas?</h3>\n<p>\nThe parser we implemented has a reasonable performance considering the simplicity of the grammar and effort we put into specifying it.\nOf course, PetitParser allows you to specify even faster parser, but at a cost of higher implementation effort.\nWe discuss optimizations of a high-performance grammar on the concrete example of a <a href=\"smalltalkOptimizations.html\">Smalltalk grammar</a> which can reach the performance of a hand-written parser.\n</p>\n<p>\nIf you know how to improve the performance even more, please share the ideas or contribute!\n</p>\n</section><section>\n<h3>Sources</h3>\n<p>\nThe sources of the html parser can be found here: \n</p><ul>\n<li><a href=\"../WebGrammar.st\"><code>WebGrammar</code></a> </li>\n<li><a href=\"../WebGrammarTest.st\"><code>WebGrammarTest</code></a></li>\n<li><a href=\"../WebParser.st\"><code>WebParser</code></a> </li>\n<li><a href=\"../WebParserTest.st\"><code>WebParserTest</code></a></li>\n<li><a href=\"../WebElement.st\"><code>WebElement</code></a></li>\n<li><a href=\"../JavascriptElement.st\"><code>JavascriptElement</code></a></li>\n<li><a href=\"../HtmlElement.st\"><code>HtmlElement</code></a></li>\n<li><a href=\"../UnknownText.st\"><code>UnknownText</code></a></li>\n</ul>\n\n<p>\nThe source for this tutorial is also part of the PetitParser2 package.\n</p>\n<p>\nThe image with the VMs for Linux, Mac OS and Windows can be found here:\n</p><p class=\"todo\">image</p>\n<a id=\"toc\"></a><section>\n<h1>Table of Contents</h1>\n<p>\nThis text is part of the <a href=\"Chapters/../../book.html\">Parsing With PetitParser2</a> series.\n</p>\n<p>\nPart I, Developer's Workflow:\n</p><ul>\n<li><a href=\"Chapters/../chapter1.html\">Extracting Javascript</a></li>\n<li><a href=\"Chapters/../chapter2.html\">From a Script to a Parser</a></li>\n<li><a href=\"Chapters/../chapter3.html\">Extracting the Structure</a></li>\n<li><a href=\"Chapters/../AST.html\">Abstract Syntax Tree</a></li>\n<li><a href=\"Chapters/../optimizations.html\">Optimizations</a></li>\n<li><a href=\"Chapters/../memoization.html\">Memoization</a></li>\n</ul>\n\n<p>\nPart II, Advanced Topics:\n</p><ul>\n<li><a href=\"Chapters/../starLazy.html\">The <code>starLazy</code> Operator</a></li>\n<li><a href=\"Chapters/../matchingTags.html\">Matching Tags</a></li>\n<li><a href=\"Chapters/../smalltalkOptimization.html\">Specializations in Detail</a></li>\n<li><a href=\"Chapters/../caches.html\">Caches in Detail</a></li>\n</ul>\n\n<p>\nGo to <a href=\"#top\">top</a>.\n\n</p></section></section></section></section>\n<hr></hr>\n<sup id=\"footnote1\">[1]  actually, it was not easy for the author of this text to pinpoint the root cause as well</sup><br/>\n","title":"Parsing with PetitParser2","Author":"Jan Kurs"}