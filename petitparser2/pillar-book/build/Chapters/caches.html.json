{"content":"<p>\nThis text is part of the <a href=\"Chapters/../../book.html\">Parsing With PetitParser2</a> series.\n</p><ul>\n<li><a href=\"Chapters/../chapter1.html\">Extracting Javascript</a></li>\n<li><a href=\"Chapters/../chapter2.html\">From Script to Parser</a></li>\n<li><a href=\"Chapters/../chapter3.html\">Extracting the Structure</a></li>\n<li><a href=\"Chapters/../AST.html\">Abstract Syntax Tree</a></li>\n<li><a href=\"Chapters/../optimizations.html\">Optimizations</a></li>\n<li><a href=\"Chapters/../memoization.html\">Memoization</a></li>\n</ul>\n\n<p>\nAdditional Chapters:\n</p><ul>\n<li><a href=\"Chapters/../matchingTags.html\">Matching Tags</a></li>\n<li><a href=\"Chapters/../smalltalkOptimization.html\">Specializations in Detail</a></li>\n<li><a href=\"Chapters/../caches.html\">Caches in Detail</a></li>\n</ul>\n\n<section>\n<h1>Caches</h1>\n\n<p>\nIn the <a href=\"./optimizations.html\">Optimizations</a> chapter we have briefly described optimizations based on specializations and caching.\nIn this text we describe the caches used by PetitParser2.\n</p>\n<p>\nPetitParser2 utilizes four different caches that can be split into two categories:\n</p>\n<ul>\n<li>First category contains fast and memory efficient caches, which remember only the last result of an underlying parser. If it happens that a parser is invoked at the same position again, the result is returned without any parsing. If the position differs, the underlying parser is invoked and the result is remembered for the new position. <s>The fast caches cannot be applied for the context-sensitive parsers, i.e. for parsers whose result depends on some other parameters than a position, e.g. the parser generated from the <code>elClose</code> rule.</s></li>\n</ul>\n\n\n<ul>\n<li>The second category contains slower and more memory intense caches that remember every result for the given position. We call these caches memoizing caches. If it happens a parser is invoked at any position it has been invoked before, the result is returned without any parsing. <s>Furthermore, if a parser is context-sensitive, the cache uses the whole context as a key.</s></li>\n</ul>\n\n\n<p>\nYou can inspect the performance of caches in the cache view:\n</p>\n<p class=\"todo\">create a screenshot with the memoization cache and fix the paragraph.</p>\n<p>\n\n<figure>\n\t<img src=\"figures/optimized-caches.png\" width=\"100%%\"/>\n\t<figcaption></figcaption>\n</figure>\n</p>\n<p>\nThere are three caches visble in the cache view: (i) cache and (ii) trimming cache belong to the first category and (iii) sea memoization cache belongs to the second category. \nWe discuss these caches briefly in the following text.\n</p>\n<section>\n<h2>1. Cache</h2>\n<p>\nCache improves performance of choice that has alternatives with the same prefix. \nConsider <code>unary</code> (e.g. <em>parser</em>) and <code>keyword</code> (e.g <em>parser:</em>) in Smalltalk:\n</p><figure><pre><code class=\"smalltalk\">(identifier, $: asPParser not) / \n(identifier, $: asPParser)</code></pre><figcaption></figcaption></figure>\n\n<p>\nNormally, if the <code>identifier</code> is not followed by <code>:</code>, the parser backtracks and parses identifier again. \nOptimizations of PetitParser2 can detect such a case and protect <code>identifier</code> with a cache, preventing superfluous invocation of <code>identifier</code>.\n</p>\n\n</section><section>\n<h2>2. Trimming Cache</h2>\n<dl><dd>The trimming cache improves the performance of grammars using trimmed tokens, e.g.:</dd>\n</dl>\n<figure><pre><code class=\"smalltalk\">keyword token trim, identifier token trim</code></pre><figcaption></figcaption></figure>\n<p>\nBecause each token trims whitespaces before and after itself, the trimming in between tokens happens twice. \nThe trimming cache prevents this. \nBecause trimming whitespace is usually rather fast operation, the trimming cache has impact only for very fast almost deterministic and context-free grammars such as <a href=\"smalltalkOptimizations.html\">Smalltalk grammar</a>.\n</p>\n\n</section><section>\n<h2>3. Memoization Cache</h2>\n<p class=\"todo\">write something </p>\n</section><section>\n<h2>4. Sea Memoization Cache</h2>\n<p>\nThe sea memoization cache is tailored to bounded seas. \nDue to the nature of bounded seas, in some cases parsing a grammar with bounded seas can result in an exponential time complexity, performing lots of redundant work. \nBecause the traditional cache would not be able to reduce the exponential overhead (it can only reduce the overhead by a constant), the seas are memoized.\nMemoization requires more memory, but it gives bounded seas the good old linear complexity.\n</p>\n\n\n</section></section>","title":"Parsing with PetitParser2","Author":"Jan Kurs"}