${inputFile:Chapters/navigation.pillar}$

!Create an Abstract Syntax Tree

In the previous chapter we tested that our grammar parses the nested elements,
but we have very limited idea how does the extracted structure look like.
The direct output of a parser is typically very detailed and not well-readable. 
It is called concrete syntax tree (CST), which is (in the case of PetitParser) array of arrays of arrays of ... with characters and strings as terminals.

It is the time to return a more convenient representation of the input: ''an abstract syntax tree'', in short AST. 
Abstract syntax tree, contrary to the very low-level and detailed concrete syntax tree, is conceptually closer to the target domain. 
In our case the domain should be some kind of a tree with html elements and javascript.


It is considered to be a good practice in PetitParser to split grammar, which returns concrete syntax tree, from parser, which returns abstract syntax tree. 
We do this by subclassing ==WebGrammar==:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[[';
	lf;
	nextPutAll: (t definitionFor: WebParser);
	lf;
	nextPutAll: ']]]'
]]]

!!Testing First

Parsing is great use case for test driven development. 
So let us start with tests first. 
Tests give us a clear idea what kind of interface we expect from abstract syntax tree:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t definitionFor: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #parserClass in: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testElement in: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testElementEmpty in: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testElementNested in: WebParserTest); lf;
	lf;
	nextPutAll: ']]]'
]]]


And for malformed elements, we expect the following results:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #testElementMalformedExtraClose in: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testElementMalformedWrongClose in: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testElementMalformedUnclosed in: WebParserTest); lf;
	lf;
	nextPutAll: ']]]'
]]]


And of course, we expect javascript code to be extracted as follows:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #testJavascript in: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testJavascriptWithString in: WebParserTest); lf;
	lf;
	nextPutAll: ']]]'
]]]

!!AST Nodes
If we want to pass these test, the result of a parse should be a tree consisting of three different nodes: 
# a javascript code; 
# an html element; and
# a text.

We define these nodes as follows, starting with its abstract predecessor ==WebElement==, which contains methods that ease our testing.

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t definitionFor: WebElement); lf;
	lf;
	nextPutAll: (t sourceFor: #children in: WebElement); lf;
	lf;
	nextPutAll: (t sourceFor: #firstChild in: WebElement); lf;
	lf;
	nextPutAll: (t sourceFor: #secondChild in: WebElement); lf;
	lf;
	nextPutAll: (t sourceFor: #gtTreeViewIn: in: WebElement); lf;
	lf;
	nextPutAll: ']]]'
]]]

==JavascriptElement== follows:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t definitionFor: JavascriptElement); lf;
	lf;
	nextPutAll: (t sourceFor: #code in: JavascriptElement); lf;
	lf;
	nextPutAll: (t sourceFor: #code: in: JavascriptElement); lf;
	lf;
	nextPutAll: (t sourceFor: #displayText in: JavascriptElement); lf;
	lf;
	nextPutAll: (t sourceFor: #gtText: in: JavascriptElement); lf;
	lf;
	nextPutAll: ']]]'
]]]

As well as ==HtmlElement==:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t definitionFor: HtmlElement); lf;
	lf;
	nextPutAll: (t sourceFor: #children in: HtmlElement); lf;
	lf;
	nextPutAll: (t sourceFor: #name in: HtmlElement); lf;
	lf;
	nextPutAll: (t sourceFor: #name: in: HtmlElement); lf;
	lf;
	nextPutAll: (t sourceFor: #displayText in: HtmlElement); lf;
	lf;
	nextPutAll: ']]]'
]]]


Last but not least ==UnknownText==:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t definitionFor: UnknownText); lf;
	lf;
	nextPutAll: (t sourceFor: #text in: UnknownText); lf;
	lf;
	nextPutAll: (t sourceFor: #text: in: UnknownText); lf;
	lf;
	nextPutAll: (t sourceFor: #gtText: in: UnknownText); lf;
	lf;
	nextPutAll: ']]]'
]]]



!!From a Grammar to a Parser

Now we override the rules of ==WebGrammar== in ==WebParser== so that the ==javascript== rule returns ==JavascriptElement==, the ==element== rule returns ==HtmlElement== and the ==text== rule returns ==UnknownText==:


[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #javascript in: WebParser); lf;
	lf;
	nextPutAll: (t sourceFor: #element in: WebParser); lf;
	lf;
	nextPutAll: (t sourceFor: #text in: WebParser); lf;
	lf;
	nextPutAll: ']]]'
]]]

And finally, for convenience, we trim whitespaces around html elements:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #elClose in: WebParser); lf;
	lf;
	nextPutAll: (t sourceFor: #elOpen in: WebParser); lf;
	lf;
	nextPutAll: ']]]'
]]]

@@note There is ==trimRight== in ==elOpen==, which means that only the whitespace on the right is trimmed. This makes caching of PetitParser slightly more efficient, because element always starts at the first non-whitespace character. If there is a trimming from left and right (using the ==trim==), it might start at any preceding whitespace or the first non-whitespace character and this would lead into lower cache-hit ratio.

By this time all the tests should pass:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t testResultsFor: #(
		#testElement
		#testElementEmpty
		#testElementNested
		#testElementMalformedUnclosed
		#testElementMalformedExtraClose
		#testElementMalformedWrongClose
		#testJavascript
		#testJavascriptWithString) in: WebParserTest); lf;
	lf;
	nextPutAll: ']]]'
]]]

!!Structured Document

Now let us construct the whole HTML document.
The pieces are already there, we just need to connect them.

In the previous chapters, we defined document (represented by the ==document== rule) in ==WebGrammar== as a repetition of javascript seas. 
Now we define a structured document (==structuredDocument==), i.e. a document with an html structure. 
Of course, we write tests first and we start with ==WebGrammarTest==:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #testStructuredDocumentSimple in: WebGrammarTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testStructuredDocumentWithDoctype in: WebGrammarTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testStructuredDocument in: WebGrammarTest); lf;
	lf;
	nextPutAll: ']]]'
]]]

From the tests we see that the root of an html file is an element that can be surrounded by some other information (e.g. doctype or comments), therefore we define structured document as an element surrounded by a sea:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #structuredDocument in: WebGrammar); lf;
	nextPutAll: ']]]'
]]]

Furthermore, we verify that we extract the correct structure of the document. 
This can be done in the ==WebParserTest==:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #testStructuredDocumentSimple in: WebParserTest); lf;
	lf;
	nextPutAll: (t sourceFor: #testStructuredDocumentWithDoctype in: WebParserTest); lf;
	lf;
	nextPutAll: '
WebParserTest>>testStructuredDocument
	| html body |
	super testStructuredDocument.
	
	self assert: result name equals: ''DOCUMENT''.

	html := result secondChild.
	self assert: html name equals: ''html''.

	self assert: html firstChild name equals: ''head''.	
	self assert: html secondChild name equals: ''body''.

'; lf;
	lf;
	nextPutAll: ']]]'
]]]


In order to pass these tests, we create a root element called ''DOCUMENT'' in ==structuredDocument==.
Furthermore we add to it the html element as well a its surroundings:

[[[eval=true
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #structuredDocument in: WebParser); lf;
	lf;
	nextPutAll: ']]]'
]]]

By this time all the tests should pass:
[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t testResultsFor: #(
		#testElement
		#testElementEmpty
		#testElementNested
		#testElementMalformedUnclosed
		#testElementMalformedExtraClose
		#testElementMalformedWrongClose
		#testJavascript
		#testJavascriptWithString
		#testStructuredDocumentSimple
		#testStructuredDocumentWithDoctype
		#testStructuredDocument) in: WebParserTest); lf;
	lf;
	nextPutAll: ']]]'
]]]

!!Comments

In this section we focus on HTML comments. 
Comments can contain scripts or other elements that are not part of the html document (they are just comments that look the same). 
And they may confuse the parser. 

Actually they do and they do so in our tests as well!
There is an error in ==WebParser== that we have not found. 
It extracts one extra HTML element, which is not part of the HTML document.
Inspect the following and switch to the tree view:

[[[
WebParser new parse: input.
]]]

There is a ''<p>'' element in the ''<body>''. 
But ''<p>'' is a part of a comment, it should not be included in the document structure. 
First, we should fix the ==testStructuredDocument== to cover this case:

[[[eval=true
| t |
t := PP2Tutorial new.
stream 
	nextPutAll: '[[['; lf;
	nextPutAll: (t sourceFor: #testStructuredDocument in: WebParserTest); lf;
	nextPutAll: ']]]'
]]]

So where does the problem come from?
The cause is the same as in the case of prematurely ended javascript.
==WebGrammar== has no notion of a comment and handles a content of a comment as an ordinary html code. 
Therefore we have to define what is an html comment:


[[[eval=true
| t |
t := PP2Tutorial new.
t printAsCode: (t sourceFor: #comment in: WebGrammar) stream: stream.
]]]

And now we can redefine ==text== so that it knows what is a comment:

[[[eval=true
| t |
t := PP2Tutorial new.
t printAsCode: (t sourceFor: #text in: WebGrammar) stream: stream.
]]]


We already mentioned in the previous text that ==starLazy== utilizes bounded seas and the above code is equivalent to:

[[[
(#epsilon asPParser)
  waterToken: (comment / #any asPParser);
  yourself	 
]]]


Because now water knows what is a comment, it skips the complete comment including the ''<p>'' element inside.


This is it, we can parse all of it!

!!Conclusion 
In this chapter we have applied the test-driven approach to define our AST nodes.
We defined ==WebParser==, wchid extends the ==WebGrammar== and builds the AST nodes.
Last but not least, we had a look how to avoid false positives caused by comments.


[[[eval=true
|t|
t := PP2Tutorial new.
t export: WebParser.
t export: WebParserTest.
t export: WebElement.
t export: JavascriptElement.
t export: HtmlElement.
t export: UnknownText.
]]]

!!!Complete Sources
You can download the sources here:
- *==WebGrammar==>../WebGrammar.st* 
- *==WebGrammarTest==>../WebGrammarTest.st*
- *==WebParser==>../WebParser.st* 
- *==WebParserTest==>../WebParserTest.st*
- *==WebElement==>../WebElement.st*
- *==JavascriptElement==>../JavascriptElement.st*
- *==HtmlElement==>../HtmlElement.st*
- *==UnknownText==>../UnknownText.st*

The source for this tutorial is also part of the PetitParser2 package.

${inputFile:Chapters/toc.pillar}$
