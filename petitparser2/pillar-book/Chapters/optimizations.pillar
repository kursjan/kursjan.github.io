${inputFile:Chapters/navigation.pillar}$

!Optimizations Overview


@@note Please note that the ==WebGrammar== exported in the previous chapter contains already optimized version of ==element== rule. In this and the following chapter, we suppose what we stated in *Extracting the Structure>chapter3.pillar* chapter about the ==element== definition, i.e. it looks like this:
[[[
WebGrammar>>element
	^ (elOpen, elContent, elClose)
]]]


!!Basic Analysis
When running the ==testStructuredDocument==, you might have noticed that the performance is not good. 
It is actually terribly bad. Let us inspect in in detail:

[[[
input := PP2Sources current htmlSample.
WebParser new debug: input.
]]]

!!!Report View
This will run the parser in a debug mode, which collects lots of useful information. Unfortunately, it also takes considerable amount of time so be patient. Once you get the result, inspect the Report tab (note that numbers might slightly differ in your case):

+>figures/unoptimized-report.png|width=100%+

The total stream size is 1171 characters. 
The parser has remembered the full context 510197 times and restored 387667 times. 
This means that the full copy of the context (including the stack of opened elements) has been created 510197 times and the context has been restored from this full copy (by doing another copy) 387667 times. 
This is in average 331 backtrackings per consumed character. 


Some of the parsers do not need to perform the full context copy. 
These are prefixed with ‘lightweight’. 
In the lightweight case, only the position is remembered and restored (which is much faster than the full copy of a stack). 
This happened in average 92 times per character.


Honestly, these numbers are brutal. 
In ideal case, the number of full restores should be zero. 
Full remember and restore is very expensive. 
Very often only lightweight remember and restore happens, since many grammars are context-free, i.e. they do not use ==push==, ==match== and ==pop== operators. 

Regarding the lightweight backtracking, the average of lightweight backtracks per character should be below 1 (in ideal case). 
This can happen in rase of deterministic grammars, which do not do any (or only a little) speculations and know exactly which alternative of a choice is the correct one. 

!!!Debug View
So why are the numbers so bad in our case? Let us inspect in more detail how this was happening, using the Debug view:

+>figures/unoptimized-debug.png|width=100%+

The view shows us that 1502165 parsers were invoked to consume the input. 
Most of it (751559 invocations) happened when parsing first two lines of the input - the before water of the sea.

This is too much for such a short input. 
Such a bad performance is caused by the fact that bounded seas have to verify at every position if the next parser can be parsed. 
If the next parser happens to be another sea (as in the case of ==WebGrammar==), the number of invocations grows really fast (exponentially in fact). 


We see that the element rule took approximately one half of the invocations (750598). 
Majority of 751559 invocations of before water were spent by testing for element. 

Another glimpse of ineffectivness can be seen in the ==elOpen== rule.

+>figures/unoptimized-elOpen.png|width=100%|label=elOpenUnoptimized+

You can see that the whole ''<html lang="html" dir="ltr" class="js-enabled">'' is parsed by invoking 272 parsers.
This is rather too much for a line with 55 characters.
One of the reasons is how are the identifiers parsed.
You can see that when recognizing the ''html'' text, 6 different parsers are invoked; for each letter one and two extra parsers.

!!Using the ==optimize== method
Luckily, PetitParser2 comes with an automated optimizations that are able to reduce most of the unnecessary overhead. 
Let it give a try:

[[[
WebParser new optimize debug: input.
]]]

The report looks much better now:
+>figures/optimized-report.png|width=100%+



Only one full remember, and only 7 lightweight backtracks per character. 
This is reasonably good for a grammar with bounded seas. 

@@note Because of the nature of bounded seas and implementation of PetitParser2, we do not recommend to parse grammars with more complicated bounded seas without optimizations.

!!!Optimization in Detail
Let us inspect some of the optimizations that happened. 
Let us try the Debug view:

+>figures/optimized-debug.png|width=100%+

We see that the total number of invoked parsers is 55144, roughly 30x less. 
We also see that, as in the previous case, most of the parsers were invoked in the before-water of the initial sea, even though roughly 10x less. 
But we can also notice that the following island and after water are parsed using only 2 and 4 parser invocations respectively! 

!!!Caches

The main reason of reduced invocations is caching. 
Under the ==element== rule, there is a mapping node. 
The mapping node returns the complete HTML element just in two invocations. 
The fact that the result has been cached is visualized via the result reference. 


The reference indicates that at the time of that invocation the result has already been computed during some previous invocation. 
The parser remembered it and it returned the result without invoking the parser again. 
This is done by the ==PP2Cache== strategy (you can see its profiling version in the screenshot). The cache has been added to the element during the optimization phase. 

More about caches can be found in the *Caching chapter>caches.pillar*.

!!!Specializations

Another optimizations applied by PetitParser two are specializations.
The way specializations work can be demonstrated on the opening of an html element: ''<html lang="mul" dir="ltr" class="js-enabled">''.

+Optimized parse of ==elOpen==>figures/optimized-elOpen.png|width=100%|label=elOpenOptimized+

One can see that the ''html'' text has been recognized using only one invocation contrary to the six invocations in the unoptimized case (see Figure *@elOpenUnoptimized*).
In the unoptimized case the ''html'' text was parsed using the ''PossessiveRepeating'' strategy.
In the optimized case (see Figure *@elOpenOptimized*) the used strategy is ''PlusPredicateObject'', which is implemented as a while loop without underlying parser invocations hence is more efficient.

The same thing happened with the mapping node. 
The specializations recognized an ''any-star-lazy'' pattern, which, in this case, means to consume any character until end of the tag ==>== appears.
This can be implemented as a single while loop saving 252 parser invocations.

@@todo More details about specializations are provided in the *Smalltalk Parser>smalltalkOptimizations.pillar* chapter.

!!Conclusion
In this text we briefly described how inefficiencies of PEG-based parser combinators and we showed how can the ==optimize== method fix most of these.

Unfortunatelly, not all the optimizations can be done automatically.
You might have noticed that we described only three out of four different caches used in the PetitParser. 
The last fourth cache is a bit special and we will dedicate a whole *Memoization>memoization.pillar* chapter to it.

${inputFile:Chapters/toc.pillar}$
